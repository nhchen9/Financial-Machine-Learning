layer_dropout(rate = 0.5) %>%
layer_dense(units = 16, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages("keras")
install.packages("keras")
install.packages("tensorflow")
)
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(3, 3), activation = "relu", input_shape = c(100, 20, 1)) %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 16, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 1, activation = "sigmoid")
library(keras)
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(3, 3), activation = "relu", input_shape = c(100, 20, 1)) %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 16, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages("abind")
k_clear_session()
library(keras)
install.packages("keras")
install.packages("tensorflow")
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(3, 3), activation = "relu", input_shape = c(100, 20, 1)) %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 16, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 1, activation = "sigmoid")
library(keras)
library(tensorflow)
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(3, 3), activation = "relu", input_shape = c(100, 20, 1)) %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 16, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 1, activation = "sigmoid")
tensorflow::install_tensorflow()
py_config()
library('reticulate')
py_config()
py_config()
library('reticulate')
py_config()
install_keras(tensorflow = "gpu")
library(keras)
install_keras(tensorflow = "gpu")
conda_version()
fracDiff = function(datc, d=.5, tau=.0001){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
for(i in 1:length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
for(i in dim(allDat)[2]){
allDat[,i] = fracDiff(allDat[,i])
}
library(keras)
library(Hmisc)
library(lubridate)
library(gtools)
library(data.table)
library(onehot)
setwd("C:/Users/nhche/Development/stat-430")
dat = read.csv("datasets/2017_M1_IEX.csv", header =F)
dat = dat[,-3]
names(dat) = c("tStamp", "ticker", "O", "H", "L", "C", "V")
## impute missing values by 0
dat$C = zoo::na.locf(dat$C)
dat$V = na.replace(dat$V, 0)
TICKER = c("SPY", "AAPL", "MSFT", "GOOGL","FB","GOOG", "INTC","AMZN", "VZ", "BRK.B",  "BAC","JNJ", "JPM", "XOM",
"PFE", "UNH", "V", "T", "WFC", "CVX", "HD")
pdat = NULL
vdat =NULL
allDat <- NULL
for(iTicker in TICKER){
tmpDat <- subset(dat, ticker==iTicker)
pdat <- cbind(pdat, tmpDat$C)
vdat <- cbind(vdat, tmpDat$V)
}
allDat = cbind(pdat, vdat)
nMin <- 390
nDay <- dim(allDat)[1] / nMin
train_days <- 1:150
val_days <- 151:200
test_days <- 201:251
train_min <- 1:(150*nMin)
val_min <- (150*nMin+1):(200*nMin)
test_min <- (200*nMin+1):(nDay*nMin)
w=60
avgMprice <- c(rep(NA, w-1), zoo::rollmean(allDat[,1], k=w, align="left"))
preMP <- avgMprice
postMP <- c(avgMprice[-(1:w)], rep(NA,w))
price_change <- postMP - preMP
r <- 0.08
Y <- rep(1, length(preMP)) # stable
Y[price_change > r] <- 2 # increase
Y[price_change < - r] <- 0 # decrease
kept_min <- ( (1:nrow(allDat)) %% nMin > w ) & ( (1:nrow(allDat)) %% nMin <= nMin - w )
Y[!kept_min] <- NA
length(which(Y==1))
length(which(Y==2))
length(which(Y==0))
y_train <- Y[train_min]
y_val <- Y[val_min]
y_test <- Y[test_min]
fracDiff = function(datc, d=.5, tau=.0001){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
for(i in 1:length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
for(i in dim(allDat)[2]){
allDat[,i] = fracDiff(allDat[,i])
}
dim(allDat)
head(allDat)
fracDiff = function(datc, d=.5, tau=.0001){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
for(i in 1:length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
for(i in 1:dim(allDat)[2]){
allDat[,i] = fracDiff(allDat[,i])
}
fracDiff = function(datc, d=.5, tau=.001){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
for(i in 1:length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
fracDiff(allDat[,1])
allDat = cbind(pdat, vdat)
allDat[,1]
fracDiff = function(datc, d=.5, tau=.001){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
print(length(w))
for(i in 1:length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
a  =fracDiff(allDat[,1])
a
fracDiff = function(datc, d=.5, tau=.0001){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
print(length(w))
for(i in 1:length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
a = fracDiff(allDat)
fracDiff = function(datc, d=.5, tau=.0003){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
print(length(w))
for(i in 1:length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
a = fracDiff(allDat)
a = fracDiff(allDat[,1])
a
fracDiff = function(datc, d=.5, tau=.0003){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
print(length(w))
for(i in w:length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
a = fracDiff(allDat[,1])
a
fracDiff = function(datc, d=.5, tau=.0003){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
print(length(w))
for(i in length(w):length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
a = fracDiff(allDat[,1])
a
tail(a)
mean(a)
mean(a, na.rm=TRUE)
allDat[,1] = a
allDat
allDat[200,]
for(i in 1:dim(allDat)[2]){
allDat[,i] = fracDiff(allDat[,i])
}
allDat[,1]
allDat[200,]
allDat = cbind(pdat, vdat)
fracDiff = function(datc, d=.5, tau=.0003){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
print(length(w))
for(i in length(w):length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
fracDiff = function(datc, d=.5, tau=.0001){
w_n = 1
w = 1
while (abs(w_n) > tau && length(w) < length(datc)){
k = length(w)
w_n = -1*w_n*(d-k+1)/k
if (abs(w_n) > tau){
w = c(w,w_n)
}
}
fracD = rep(NA, length(datc))
print(length(w))
for(i in length(w):length(datc)){
temp = 0
for(j in 1:length(w)){
if (j==i){break}
temp = temp + datc[i-j+1] * w[j]
}
fracD[i] = temp
}
fracD
}
a = fracDiff(allDat[,1])
for(i in 1:21){
allDat[,i] = fracDiff(allDat[,i])
}
NA > 0
1>0
which(allDat[,1] > NA)
which(allDat[,1] >0)
which(!is.na(allDat[,1]))
length(which(!is.na(allDat[,1])))
97691+199
for(i in 22:42){
m = mean(x_train[,i])
s = sd(x_train[,i])
x_train = (x_train - m)/s
x_val = (x_val-m)/s
x_test = (x_test-m)/s
}
x_train <- allDat[train_min, col_included]
col_included <- 1:(length(TICKER)*2)
x_train <- allDat[train_min, col_included]
x_val <- allDat[val_min, col_included]
x_test <- allDat[test_min, col_included]
for(i in 22:42){
m = mean(x_train[,i])
s = sd(x_train[,i])
x_train = (x_train - m)/s
x_val = (x_val-m)/s
x_test = (x_test-m)/s
}
sampling_generator <- function(X_data, Y_data, batch_size, w)
{
function()
{
rows_with_up_down <- w:nrow(X_data)
rows_with_up_down <- intersect(rows_with_up_down, which( Y_data %in% c(0,1,2)), which(!is.na(X_data[,1])))  # only use labels 0 and 1
rows <- sample( rows_with_up_down, batch_size, replace = TRUE )
X = array(dim=c(batch_size, w, 21,2))
Ylist = list()
for(i in 1:length(rows)){
X[i,,,1]=X_data[(rows[i]-w+1):rows[i],1:21]
X[i,,,2]=X_data[(rows[i]-w+1):rows[i],22:42]
Ylist[[i]] = c(0,0,0)
Ylist[[i]][Y_data[rows[i]]+1] = 1
}
#print(Ylist)
Y <- array(abind::abind(Ylist, along = 0), c(batch_size, 3))
list(X, Y)
}
}
k_clear_session()
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(4, 4), activation = "relu",input_shape = c(60, 21, 2)) %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 32, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 3, activation = "softmax")
summary(model)
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 1e-4),
metrics = c("accuracy")
)
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(4, 4), activation = "relu",input_shape = c(60, 21, 2)) %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 32, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 3, activation = "softmax")
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(4, 4), activation = "relu",input_shape = c(60, 21, 2)) %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 32, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 3, activation = "softmax")
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(4, 4), activation = "relu",input_shape = c(60, 21, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 32, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 3, activation = "softmax")
library(keras)
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(4, 4), activation = "relu",input_shape = c(60, 21, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 32, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 3, activation = "softmax")
py_config()
library(reticulate)
py_config()
library(keras)
k_clear_session()
library(keras)
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 6, kernel_size = c(4, 4), activation = "relu",input_shape = c(60, 21, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_conv_2d(filters = 8, kernel_size = c(3, 3), activation = "relu") %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_flatten() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 32, activation = "relu", kernel_regularizer = regularizer_l1(0.001)) %>%
layer_dense(units = 3, activation = "softmax")
